{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kniemi641/UC-MScA/blob/master/ML%20Homework%207%20-%20RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gnLAMNfJQgzq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 7 - RNN\n",
        "\n",
        "The purpose of this exercise is to train a recurrent neural network model to identify malicous networking activity. A networking log file has been provided which contains attributes such as timestamp, access method, and an indicator which denotes if the observed activity was a breach."
      ]
    },
    {
      "metadata": {
        "id": "CJShQc4F9Fkb",
        "colab_type": "code",
        "outputId": "07de4b17-7089-4b4a-cf0c-277be7595554",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "cell_type": "code",
      "source": [
        "# Generic Packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from scipy import stats\n",
        "import sys\n",
        "import json\n",
        "from scipy import stats\n",
        "import optparse\n",
        "\n",
        "#Neural Networks\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense, Dropout, GaussianDropout\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import np_utils\n",
        "from collections import OrderedDict\n",
        "from keras import optimizers\n",
        "import h5py\n",
        "\n",
        "# Sklearn Packages\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#Plotting Packages\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "import seaborn as sns\n",
        "\n",
        "#Utilitie warnings\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')\n",
        "#uploaded = files.upload()\n",
        "np.random.seed(235)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nCxaupIB-HUF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GLOBAL & CONSTANTS\n",
        "NUM = 7\n",
        "INPUT_DATA_FILE = 'dev-access.csv'\n",
        "\n",
        "GD_CODE_DIR = '/content/gdrive/My Drive/Code/uchicago/'\n",
        "SUBJECT_DIR = 'Machine Learning & Predictive Analytics/'\n",
        "DATA_DIR = 'data/'\n",
        "MODEL_DIR = 'models/'\n",
        "LOGS_DIR = 'logs/'\n",
        "HOMEWORK_DIR = 'Homework {}/'.format(NUM)\n",
        "NOTEBOOK_NAME = 'Homework {}.ipynb'.format(NUM)\n",
        "\n",
        "MAIN_PATH = os.path.join(GD_CODE_DIR\n",
        "                        ,SUBJECT_DIR\n",
        "                        ,HOMEWORK_DIR)\n",
        "\n",
        "INPUT_FILE = os.path.join(MAIN_PATH\n",
        "                          ,DATA_DIR\n",
        "                          ,INPUT_DATA_FILE)\n",
        "\n",
        "NOTEBOOK_FILE = os.path.join(MAIN_PATH\n",
        "                            ,NOTEBOOK_NAME)\n",
        "\n",
        "MODEL_EXPORT_PATH = os.path.join(MAIN_PATH\n",
        "                                ,MODEL_DIR)\n",
        "\n",
        "LOG_PATH = os.path.join(MAIN_PATH\n",
        "                       ,LOGS_DIR)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LQFiY_pQp8uQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n",
        "The dataset is imported in .JSON format and flattened into a X and y vectors.\n"
      ]
    },
    {
      "metadata": {
        "id": "2Zz715k5-sVe",
        "colab_type": "code",
        "outputId": "9f834996-0527-4806-a67c-0849754da5cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "log_data = pd.read_csv(INPUT_FILE, engine='python', quotechar='|', header=None)\n",
        "dataset = log_data.values\n",
        "\n",
        "X = dataset[:,0]\n",
        "y = dataset[:,1]\n",
        "\n",
        "for index, item in enumerate(X):\n",
        "# Quick hack to space out json elements\n",
        "  reqJson = json.loads(item, object_pairs_hook=OrderedDict)\n",
        "  del reqJson['timestamp']\n",
        "  del reqJson['headers']\n",
        "  del reqJson['source']\n",
        "  del reqJson['route']\n",
        "  del reqJson['responsePayload']\n",
        "X[index] = json.dumps(reqJson, separators=(',', ':'))\n",
        "print('X data: {}'.format(X[:5]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X data: ['{\"timestamp\":1502738402847,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"accept-language\":\"en-us\",\"accept-encoding\":\"gzip, deflate\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"referer\":\"http://localhost:8002/enter\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"content-type\":\"application/json\",\"content-length\":\"36\"},\"requestPayload\":{\"username\":\"Carl2\",\"password\":\"bo\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}'\n",
            " '{\"timestamp\":1502738402849,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"88.141.113.237\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"47\"},\"requestPayload\":{\"username\":\"pafzah\",\"password\":\"worldburn432\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}'\n",
            " '{\"timestamp\":1502738402852,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"205.49.83.118\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"44\"},\"requestPayload\":{\"username\":\"Panos1\",\"password\":\"najrijkom\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}'\n",
            " '{\"timestamp\":1502738402852,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"205.49.83.118\",\"referer\":\"http://localhost:8002/enter\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"accept-language\":\"en-us\",\"accept-encoding\":\"gzip, deflate\",\"connection\":\"keep-alive\",\"accept\":\"*/*\",\"referer\":\"http://localhost:8002/enter\",\"cache-control\":\"no-cache\",\"x-requested-with\":\"XMLHttpRequest\",\"content-type\":\"application/json\",\"content-length\":\"47\"},\"requestPayload\":{\"username\":\"vuvpuvehu\",\"password\":\"password1\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}'\n",
            " '{\"timestamp\":1502738402853,\"method\":\"post\",\"query\":{},\"path\":\"/login\",\"statusCode\":401,\"source\":{\"remoteAddress\":\"137.196.95.116\"},\"route\":\"/login\",\"headers\":{\"host\":\"localhost:8002\",\"connection\":\"keep-alive\",\"cache-control\":\"no-cache\",\"accept\":\"*/*\",\"accept-encoding\":\"gzip, deflate, br\",\"accept-language\":\"en-US,en;q=0.8,es;q=0.6\",\"content-type\":\"application/json\",\"content-length\":\"41\"},\"requestPayload\":{\"username\":\"Michele\",\"password\":\"mokgu\"},\"responsePayload\":{\"statusCode\":401,\"error\":\"Unauthorized\",\"message\":\"Invalid Login\"}}']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ooH81FTakiQ9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next the X vector is tokenized at the character level, using tabs and line carriage returns as filters. The observations are padded to the max_log_length."
      ]
    },
    {
      "metadata": {
        "id": "ut5mx7gd9WFF",
        "colab_type": "code",
        "outputId": "a7565f0d-28df-4aa3-e657-27d39369326e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "cell_type": "code",
      "source": [
        "#Tokenize X by tabs and cariage returns\n",
        "tokenizer = Tokenizer(filters='\\t\\n', char_level=True)\n",
        "tokenizer.fit_on_texts(X)\n",
        "\n",
        "num_words = len(tokenizer.word_index)+1\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "max_log_length = 1024\n",
        "X_processed = sequence.pad_sequences(X, maxlen=max_log_length)\n",
        "X_processed[:5]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0,  0,  0, ...,  1, 27, 27],\n",
              "       [ 0,  0,  0, ...,  1, 27, 27],\n",
              "       [ 0,  0,  0, ...,  1, 27, 27],\n",
              "       [ 0,  0,  0, ...,  1, 27, 27],\n",
              "       [ 0,  0,  0, ...,  1, 27, 27]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "tvBzfCVEknRZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The code is split into train and test using a ratio of 3:1."
      ]
    },
    {
      "metadata": {
        "id": "veLTSth2Wskp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.25, random_state=235)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_bl6hx1jBuS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 1"
      ]
    },
    {
      "metadata": {
        "id": "tjIFfDbHQwsb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The first model is constructed using an embedding layer, LSTM layer, and a dense layer. The embedding layer as input dimensions equal to the processed X vector, and an output dimension of 32. The LSTM layer uses 64 units, with a dropout rate of 0.5. Finally the dense layer is single unit with a 'Rectified Linear Unit' activation function. "
      ]
    },
    {
      "metadata": {
        "id": "hVUxc7iW9qIf",
        "colab_type": "code",
        "outputId": "924db666-613c-4cd9-fd2f-684aa93a939b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "cell_type": "code",
      "source": [
        "#Sequential Model\n",
        "model_1 = Sequential()\n",
        "\n",
        "#Embedding Input Layer\n",
        "model_1.add(Embedding(input_dim=num_words\n",
        "                      , output_dim = 32\n",
        "                      , input_length = max_log_length)\n",
        "            )\n",
        "\n",
        "#LSTM Lyaer\n",
        "model_1.add(LSTM(units = 64\n",
        "                , dropout= 0.5)\n",
        "            )\n",
        "\n",
        "#Output Layer\n",
        "model_1.add(Dense(units = 1\n",
        "                  , activation= 'relu',)\n",
        "            )\n",
        "\n",
        "#Compile\n",
        "model_1.compile(optimizer='Adam'\n",
        "                , loss='binary_crossentropy'\n",
        "                , metrics=['accuracy']\n",
        "                )\n",
        "\n",
        "print(model_1.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 1024, 32)          2048      \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 26,945\n",
            "Trainable params: 26,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "voI7I5DTHq0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model summary above shows the 3 layers, their dimensions, and the total number of trainable parameters. The model is then trained using 3 epochs, with a validation split of 3:1 and a batch size of 128."
      ]
    },
    {
      "metadata": {
        "id": "1-QS-SDXgZfa",
        "colab_type": "code",
        "outputId": "3afe1333-340d-411f-b32c-bc4957edf505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#Histrial training\n",
        "model_1_history = model_1.fit( X_train\n",
        "                              ,y_train\n",
        "                              ,batch_size=128\n",
        "                              ,epochs=3\n",
        "                              ,validation_split=0.25\n",
        "                              ,verbose=1\n",
        "                             )\n",
        "\n",
        "model_1.save(MODEL_EXPORT_PATH+'model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15059 samples, validate on 5020 samples\n",
            "Epoch 1/3\n",
            "15059/15059 [==============================] - 382s 25ms/step - loss: 0.6836 - acc: 0.6553 - val_loss: 0.4583 - val_acc: 0.7375\n",
            "Epoch 2/3\n",
            "15059/15059 [==============================] - 378s 25ms/step - loss: 0.5266 - acc: 0.6765 - val_loss: 0.4392 - val_acc: 0.7466\n",
            "Epoch 3/3\n",
            "15059/15059 [==============================] - 383s 25ms/step - loss: 0.4418 - acc: 0.7145 - val_loss: 0.4351 - val_acc: 0.6456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AXJE546sJCD6",
        "colab_type": "code",
        "outputId": "661db52c-0204-4867-95da-caa827fee732",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#model_1 = load_model(MODEL_EXPORT_PATH+'model_1.h5')\n",
        "score_1 = model_1.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:{}'.format(round(score_1[0], 4)))\n",
        "print('Test accuracy{}'.format(round(score_1[1],4)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss:0.4422\n",
            "Test accuracy0.6421\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lEQ58Ou8H60j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The results above show the accuracy and loss of the model."
      ]
    },
    {
      "metadata": {
        "id": "9nuzKqgijERY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 2\n",
        "\n",
        "The second model has the same embedding and LSTM layers as the first.Two additional dropout layers with a values of 0.5 are added, and the output layer's activation function is changed to a 'sigmoid'"
      ]
    },
    {
      "metadata": {
        "id": "iz-mWQpARGoS",
        "colab_type": "code",
        "outputId": "234106cf-b5c8-4b91-ea6d-8b16a22f936c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "cell_type": "code",
      "source": [
        "#Sequential Model\n",
        "model_2 = Sequential()\n",
        "\n",
        "#Embedding Input Layer\n",
        "model_2.add(Embedding(input_dim=num_words\n",
        "                      , output_dim = 32\n",
        "                      , input_length = max_log_length)\n",
        "           )\n",
        "\n",
        "#Dropout Layer\n",
        "model_2.add(Dropout(rate=0.5))\n",
        "\n",
        "#LSTM Lyaer\n",
        "model_2.add(LSTM(units = 64\n",
        "                 , dropout= 0.5)\n",
        "           )\n",
        "\n",
        "#Dropout Layer\n",
        "model_2.add(Dropout(rate=0.5))\n",
        "\n",
        "#Dense Sigmoid to target\n",
        "model_2.add(Dense(units = 1\n",
        "                  , activation= 'sigmoid')\n",
        "           )\n",
        "\n",
        "#Compile\n",
        "model_2.compile(optimizer='Adam'\n",
        "                , loss='binary_crossentropy'\n",
        "                , metrics=['accuracy']\n",
        "               )\n",
        "\n",
        "#summarize\n",
        "print(model_2.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 1024, 32)          2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_7 (LSTM)                (None, 64)                24832     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 26,945\n",
            "Trainable params: 26,945\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3YnDoVDtIiM2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The summary of the model above the additional layers. Note these layers have no trainable parameters (weights) and therefore the second model has the same number of trainable parameters as the first model."
      ]
    },
    {
      "metadata": {
        "id": "TuljpxWWhww1",
        "colab_type": "code",
        "outputId": "9d23ef64-fb28-47c7-a072-99f98b790e38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "cell_type": "code",
      "source": [
        "#Fit Model\n",
        "model_2_history = model_2.fit(X_train\n",
        "                              , y_train\n",
        "                              , batch_size=128                              \n",
        "                              , epochs=3\n",
        "                              , validation_split=0.25\n",
        "                              , verbose=1\n",
        "                             )\n",
        "\n",
        "model_2.save(MODEL_EXPORT_PATH+'model_2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15059 samples, validate on 5020 samples\n",
            "Epoch 1/3\n",
            "15059/15059 [==============================] - 370s 25ms/step - loss: 0.5703 - acc: 0.7096 - val_loss: 0.4643 - val_acc: 0.7466\n",
            "Epoch 2/3\n",
            "15059/15059 [==============================] - 369s 25ms/step - loss: 0.4664 - acc: 0.7402 - val_loss: 0.4479 - val_acc: 0.7466\n",
            "Epoch 3/3\n",
            "15059/15059 [==============================] - 369s 24ms/step - loss: 0.4558 - acc: 0.7404 - val_loss: 0.4469 - val_acc: 0.7466\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ko_SewvY-x6l",
        "colab_type": "code",
        "outputId": "a7d8c6c3-937a-4a0a-bf64-8fc21b274cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#model_2 = load_model(MODEL_EXPORT_PATH+'model_2.h5')\n",
        "score_2 = model_2.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:{}'.format(round(score_2[0], 4)))\n",
        "print('Test accuracy{}'.format(round(score_2[1],4)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss:0.4539\n",
            "Test accuracy0.7399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jAkC89DZj6du",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model 3"
      ]
    },
    {
      "metadata": {
        "id": "kRfh5IZAJHtp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The third model is created using the same embedding and output (dense) layer parameters. However the dropout layers have been changed to a Guassian layer and additional LSTM layer has been added. The optimizer has been changed to Stochatic Gradient Descent with a learning rate of 0.1 and momentum of 0.9 "
      ]
    },
    {
      "metadata": {
        "id": "0ahDNeBk9zdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "5cdd11f6-e4b9-47a4-bde5-0b8d01f1e89f"
      },
      "cell_type": "code",
      "source": [
        "#Sequential Model\n",
        "model_3 = Sequential()\n",
        "\n",
        "#Embedding Input Layer\n",
        "model_3.add(Embedding(input_dim=num_words\n",
        "                      , output_dim = 32\n",
        "                      , input_length = max_log_length)\n",
        "           )\n",
        "\n",
        "#Dropout Layer\n",
        "model_3.add(Dropout(rate=0.5))\n",
        "\n",
        "#LSTM Lyaer\n",
        "model_3.add(LSTM(units = 64\n",
        "                 , recurrent_dropout=0.5\n",
        "                 , activation='tanh'\n",
        "                 , return_sequences=True)\n",
        "           )\n",
        "\n",
        "#Dropout Layer\n",
        "model_3.add(Dropout(rate=0.5))\n",
        "\n",
        "model_3.add(LSTM(units = 64\n",
        "                 , recurrent_dropout=0.5\n",
        "                 , activation='tanh')\n",
        "           )\n",
        "\n",
        "#Dense Sigmoid to target\n",
        "model_3.add(Dense(units = 1\n",
        "                  , activation= 'sigmoid'\n",
        "                 )\n",
        "           )\n",
        "\n",
        "#SGD Optimizer\n",
        "SGD = optimizers.SGD(lr=0.01\n",
        "                     , decay=1e-6\n",
        "                     , momentum=0.9\n",
        "                     , nesterov=True)\n",
        "\n",
        "\n",
        "# Compiler           \n",
        "model_3.compile(optimizer=SGD\n",
        "              , loss='binary_crossentropy'\n",
        "              , metrics=['accuracy']\n",
        "               )\n",
        "            \n",
        "print(model_3.summary())   "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1024, 32)          2048      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1024, 32)          0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 1024, 64)          24832     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024, 64)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 59,969\n",
            "Trainable params: 59,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JUlrVGG_Jl7T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The summary from the model above shows the large increase in the number of trainable parameters due to to the second LSTM layer. "
      ]
    },
    {
      "metadata": {
        "id": "8H4xUc1ceRuh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "26e7f3f5-d62a-4a1e-99f4-5e01ed1bbb48"
      },
      "cell_type": "code",
      "source": [
        "#Fit Model\n",
        "model_3_history = model_3.fit(X_train\n",
        "            , y_train\n",
        "            , validation_split=0.25\n",
        "            , epochs=3\n",
        "            , batch_size=128\n",
        "            , verbose=1\n",
        "           )\n",
        "\n",
        "model_3.save(MODEL_EXPORT_PATH+'model_3.h5')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 15059 samples, validate on 5020 samples\n",
            "Epoch 1/3\n",
            "15059/15059 [==============================] - 885s 59ms/step - loss: 0.6925 - acc: 0.5279 - val_loss: 0.6915 - val_acc: 0.4970\n",
            "Epoch 2/3\n",
            "15059/15059 [==============================] - 948s 63ms/step - loss: 0.6898 - acc: 0.5714 - val_loss: 0.6871 - val_acc: 0.7466\n",
            "Epoch 3/3\n",
            "15059/15059 [==============================] - 1154s 77ms/step - loss: 0.6796 - acc: 0.6530 - val_loss: 0.6643 - val_acc: 0.7018\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B74A_JNhDSt5",
        "colab_type": "code",
        "outputId": "6cb6dcd7-2842-4101-ce71-752c86c59526",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#model_3 = load_model(MODEL_EXPORT_PATH+'model_3.h5')\n",
        "\n",
        "score_3 = model_3.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss: {}'.format(round(score_3[0], 4)))\n",
        "print('Test accuracy: {}'.format(round(score_3[1],4)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss:0.6645\n",
            "Test accuracy0.706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4X64ybEvj8gw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Analysis\n",
        "\n",
        "\n",
        "\n",
        "5.   The relu activation function has no upper bound, and the lower bound set to 0. The sigmoid function can only achieve values between 0 and 1. \n",
        "6.   The sigmoid is more appropriate for binary classification.\n",
        "7.   Dropout layers set a fraction of random inputs to 0 at each training update. This helps prevent overfitting by forcing the network to not become reliant on any one individual pathway. These inputs are NOT set to 0 during test, as testing should involve looking at all possible trained parameters. \n",
        "8.   Recurrent neural networks allow for 'memory' to help train the weights when input data is being trained. CNNs do not have this property, they are designed more to features more related to 'spacial' aspects, such as images.\n",
        "9.   LSTMs use neural network units which consist of a cell, input gate, output gate and forget gate. These gates allow for the storage, usage, discarding of information in a LSTM unit. They allowed for incorporation of training data where an unknown time lag exist between input observations."
      ]
    },
    {
      "metadata": {
        "id": "KqO2iTKIFlEj",
        "colab_type": "code",
        "outputId": "481ff43b-3b9d-4faa-de73-b54fcbee40bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html '/content/gdrive/My Drive/Code/Machine Learning & Predictive Analytics/Homework 7/Homework 7.ipynb'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/gdrive/My Drive/Code/Machine Learning & Predictive Analytics/Homework 7/Homework 7.ipynb to html\n",
            "[NbConvertApp] Writing 319663 bytes to /content/gdrive/My Drive/Code/Machine Learning & Predictive Analytics/Homework 7/Homework 7.html\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}