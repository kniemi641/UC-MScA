{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Homework 2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kniemi641/UC-MScA/blob/master/Homework_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "f_X4OPFe-Wu-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Homework 2\n",
        "\n",
        "The purpose of this exercise is to use the gradient descent to solve for the best model parameters for a multivariate linear regression. This is a continuation of the Homework 1, inorder to prove that gradient descent can be used to *fit* for the optimum parameters of any model with a cost function. In this case we are proving it can be used to solve for the analytical solution for a linear regression.\n",
        "\n",
        "Since this a continuation, I will give a brief overview of the explatory analysis which was already performed :\n",
        "\n",
        "* Data is imported, observations containing null values in either the predictor or response variables are excluded.\n",
        "\n",
        "* There are outlier observations with STheta values ~10x larger than the mean. These have been removed. \n",
        "* A ones column is appended to the predictor set to solve for the intercept parameter\n"
      ]
    },
    {
      "metadata": {
        "id": "85p9M8Emk1_A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Packages & Variables\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "BQemmtCF-Wu1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Generic packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from scipy import stats\n",
        "\n",
        "# sklearn model packages\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# plotting packages\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['axes.labelsize'] = 14\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "# utility stuff\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "np.random.seed(235)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-qS6imjDFSJ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#GLOBAL & CONSTANTS\n",
        "\n",
        "# dynamic\n",
        "NUM = 2\n",
        "INPUT_DATA_FILE = 'bottle.csv'\n",
        "\n",
        "# static\n",
        "GD_CODE_DIR = '/content/gdrive/My Drive/Code/uchicago/'\n",
        "SUBJECT_DIR = 'Machine Learning & Predictive Analytics/'\n",
        "DATA_DIR = 'data/'\n",
        "MODEL_DIR = 'models/'\n",
        "LOGS_DIR = 'logs/'\n",
        "HOMEWORK_DIR = 'Homework {}/'.format(NUM)\n",
        "NOTEBOOK_NAME = 'Homework {}.ipynb'.format(NUM)\n",
        "\n",
        "\n",
        "MAIN_PATH = os.path.join(GD_CODE_DIR\n",
        "                        ,SUBJECT_DIR\n",
        "                        ,HOMEWORK_DIR)\n",
        "\n",
        "INPUT_FILE = os.path.join(MAIN_PATH\n",
        "                          ,DATA_DIR\n",
        "                          ,INPUT_DATA_FILE)\n",
        "\n",
        "NOTEBOOK_FILE = os.path.join(MAIN_PATH\n",
        "                            ,NOTEBOOK_NAME)\n",
        "\n",
        "MODEL_EXPORT_PATH = os.path.join(MAIN_PATH\n",
        "                                ,MODEL_DIR)\n",
        "\n",
        "LOG_PATH = os.path.join(MAIN_PATH\n",
        "                       ,LOGS_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gsOFVgsPadT_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exploratory Analysis\n",
        "\n",
        "See Homework 1"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "uk0tqqisJs2Z",
        "outputId": "96e4b832-0e34-45a8-a5ee-ac5dc6ce2d48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1122
        }
      },
      "cell_type": "code",
      "source": [
        "#Load data and take a look at it\n",
        "water_data = pd.read_csv(INPUT_FILE)\n",
        "water_df = pd.DataFrame(water_data)\n",
        "\n",
        "water_data.head(5)\n",
        "print(water_df.describe())\n",
        "print('\\n Columns from input file: \\n {}'.format(water_data.columns))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Cst_Cnt        Btl_Cnt         Depthm         T_degC  \\\n",
            "count  864863.000000  864863.000000  864863.000000  853900.000000   \n",
            "mean    17138.790958  432432.000000     226.831951      10.799677   \n",
            "std     10240.949817  249664.587269     316.050259       4.243825   \n",
            "min         1.000000       1.000000       0.000000       1.440000   \n",
            "25%      8269.000000  216216.500000      46.000000       7.680000   \n",
            "50%     16848.000000  432432.000000     125.000000      10.060000   \n",
            "75%     26557.000000  648647.500000     300.000000      13.880000   \n",
            "max     34404.000000  864863.000000    5351.000000      31.140000   \n",
            "\n",
            "              Salnty         O2ml_L         STheta          O2Sat  \\\n",
            "count  817509.000000  696201.000000  812174.000000  661274.000000   \n",
            "mean       33.840350       3.392468      25.819394      57.103779   \n",
            "std         0.461843       2.073256       1.167787      37.094137   \n",
            "min        28.431000      -0.010000      20.934000      -0.100000   \n",
            "25%        33.488000       1.360000      24.965000      21.100000   \n",
            "50%        33.863000       3.440000      25.996000      54.400000   \n",
            "75%        34.196900       5.500000      26.646000      97.600000   \n",
            "max        37.034000      11.130000     250.784000     214.100000   \n",
            "\n",
            "         Oxy_µmol/Kg         BtlNum    ...             R_CHLA        R_PHAEO  \\\n",
            "count  661268.000000  118667.000000    ...      225276.000000  225275.000000   \n",
            "mean      148.808694      10.497426    ...           0.450225       0.198599   \n",
            "std        90.187533       6.189688    ...           1.208566       0.376539   \n",
            "min        -0.434900       0.000000    ...          -0.010000      -3.890000   \n",
            "25%        60.915470       5.000000    ...           0.050000       0.050000   \n",
            "50%       151.064150      10.000000    ...           0.160000       0.110000   \n",
            "75%       240.379600      16.000000    ...           0.390000       0.230000   \n",
            "max       485.701800      25.000000    ...          66.110000      65.300000   \n",
            "\n",
            "              R_PRES         R_SAMP         DIC1         DIC2          TA1  \\\n",
            "count  864863.000000  122006.000000  1999.000000   224.000000  2084.000000   \n",
            "mean      228.395694     162.071521  2153.239714  2168.148330  2256.055845   \n",
            "std       319.456731      85.722796   112.995202   154.852332    34.844435   \n",
            "min         0.000000       0.000000  1948.850000  1969.440000  2181.570000   \n",
            "25%        46.000000     200.000000  2028.330000  2008.977500  2230.322500   \n",
            "50%       126.000000     206.000000  2170.640000  2265.885000  2244.325000   \n",
            "75%       302.000000     214.000000  2253.810000  2315.525000  2278.505000   \n",
            "max      5458.000000     424.000000  2367.800000  2364.420000  2434.900000   \n",
            "\n",
            "               TA2        pH2        pH1  \n",
            "count   234.000000  10.000000  84.000000  \n",
            "mean   2278.858803   7.948570   7.910983  \n",
            "std      58.496495   0.021216   0.077666  \n",
            "min    2198.150000   7.923100   7.618300  \n",
            "25%    2229.062500   7.931475   7.898675  \n",
            "50%    2247.505000   7.946650   7.928850  \n",
            "75%    2316.452500   7.963300   7.955100  \n",
            "max    2437.000000   7.988300   8.047700  \n",
            "\n",
            "[8 rows x 70 columns]\n",
            "\n",
            " Columns from input file: \n",
            " Index(['Cst_Cnt', 'Btl_Cnt', 'Sta_ID', 'Depth_ID', 'Depthm', 'T_degC',\n",
            "       'Salnty', 'O2ml_L', 'STheta', 'O2Sat', 'Oxy_µmol/Kg', 'BtlNum',\n",
            "       'RecInd', 'T_prec', 'T_qual', 'S_prec', 'S_qual', 'P_qual', 'O_qual',\n",
            "       'SThtaq', 'O2Satq', 'ChlorA', 'Chlqua', 'Phaeop', 'Phaqua', 'PO4uM',\n",
            "       'PO4q', 'SiO3uM', 'SiO3qu', 'NO2uM', 'NO2q', 'NO3uM', 'NO3q', 'NH3uM',\n",
            "       'NH3q', 'C14As1', 'C14A1p', 'C14A1q', 'C14As2', 'C14A2p', 'C14A2q',\n",
            "       'DarkAs', 'DarkAp', 'DarkAq', 'MeanAs', 'MeanAp', 'MeanAq', 'IncTim',\n",
            "       'LightP', 'R_Depth', 'R_TEMP', 'R_POTEMP', 'R_SALINITY', 'R_SIGMA',\n",
            "       'R_SVA', 'R_DYNHT', 'R_O2', 'R_O2Sat', 'R_SIO3', 'R_PO4', 'R_NO3',\n",
            "       'R_NO2', 'R_NH4', 'R_CHLA', 'R_PHAEO', 'R_PRES', 'R_SAMP', 'DIC1',\n",
            "       'DIC2', 'TA1', 'TA2', 'pH2', 'pH1', 'DIC Quality Comment'],\n",
            "      dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "scrolled": false,
        "id": "XnqYMrKo-Wu_",
        "colab_type": "code",
        "outputId": "fa1abf0e-abde-4d2e-952f-c2f876bd7b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "cell_type": "code",
      "source": [
        "# From Homework 1, remove outliers and NAs\n",
        "water_df_clean = water_df[water_df.Salnty.notnull() \n",
        "                          & water_df.STheta.notnull() \n",
        "                          & water_df.T_degC.notnull()]\n",
        "\n",
        "predictors = ['Salnty', 'STheta']\n",
        "response = ['T_degC']\n",
        "\n",
        "print(water_df_clean.describe())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             Cst_Cnt        Btl_Cnt         Depthm         T_degC  \\\n",
            "count  812174.000000  812174.000000  812174.000000  812174.000000   \n",
            "mean    17730.743314  446791.897298     222.434704      10.847904   \n",
            "std     10079.691018  245798.556428     308.778427       4.221005   \n",
            "min         1.000000       1.000000       0.000000       1.440000   \n",
            "25%      9209.000000  240468.250000      47.000000       7.750000   \n",
            "50%     17873.000000  451139.500000     125.000000      10.100000   \n",
            "75%     26984.000000  659663.750000     300.000000      13.910000   \n",
            "max     34404.000000  864863.000000    5351.000000      31.140000   \n",
            "\n",
            "              Salnty         O2ml_L         STheta          O2Sat  \\\n",
            "count  812174.000000  661268.000000  812174.000000  661270.000000   \n",
            "mean       33.842424       3.416076      25.819394      57.103825   \n",
            "std         0.461567       2.068615       1.167787      37.094054   \n",
            "min        28.431000      -0.010000      20.934000      -0.100000   \n",
            "25%        33.490000       1.400000      24.965000      21.100000   \n",
            "50%        33.869200       3.470000      25.996000      54.400000   \n",
            "75%        34.198000       5.510000      26.646000      97.600000   \n",
            "max        37.034000      11.130000     250.784000     214.100000   \n",
            "\n",
            "         Oxy_µmol/Kg         BtlNum    ...             R_CHLA        R_PHAEO  \\\n",
            "count  661268.000000  116540.000000    ...      221495.000000  221497.000000   \n",
            "mean      148.808694      10.362751    ...           0.432899       0.190401   \n",
            "std        90.187533       6.110834    ...           1.158908       0.344446   \n",
            "min        -0.434900       0.000000    ...          -0.010000      -3.890000   \n",
            "25%        60.915470       5.000000    ...           0.050000       0.050000   \n",
            "50%       151.064150      10.000000    ...           0.160000       0.110000   \n",
            "75%       240.379600      15.000000    ...           0.380000       0.230000   \n",
            "max       485.701800      25.000000    ...          66.110000      65.300000   \n",
            "\n",
            "              R_PRES         R_SAMP         DIC1         DIC2          TA1  \\\n",
            "count  812174.000000  119877.000000  1999.000000   224.000000  2084.000000   \n",
            "mean      223.929593     161.225882  2153.239714  2168.148330  2256.055845   \n",
            "std       312.083237      86.075472   112.995202   154.852332    34.844435   \n",
            "min         0.000000       0.000000  1948.850000  1969.440000  2181.570000   \n",
            "25%        47.000000     200.000000  2028.330000  2008.977500  2230.322500   \n",
            "50%       126.000000     206.000000  2170.640000  2265.885000  2244.325000   \n",
            "75%       302.000000     213.000000  2253.810000  2315.525000  2278.505000   \n",
            "max      5458.000000     424.000000  2367.800000  2364.420000  2434.900000   \n",
            "\n",
            "               TA2        pH2        pH1  \n",
            "count   234.000000  10.000000  84.000000  \n",
            "mean   2278.858803   7.948570   7.910983  \n",
            "std      58.496495   0.021216   0.077666  \n",
            "min    2198.150000   7.923100   7.618300  \n",
            "25%    2229.062500   7.931475   7.898675  \n",
            "50%    2247.505000   7.946650   7.928850  \n",
            "75%    2316.452500   7.963300   7.955100  \n",
            "max    2437.000000   7.988300   8.047700  \n",
            "\n",
            "[8 rows x 70 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yZm7vy0Xnn-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a2d0fb70-9250-4c4a-b323-224b74af1a9d"
      },
      "cell_type": "code",
      "source": [
        "X_df = water_df_clean[predictors]\n",
        "y_df = water_df_clean[response]\n",
        "\n",
        "stheta_cut_off = 100\n",
        "\n",
        "# from HW 1 we know there are some STheta outliers\n",
        "y = y_df[X_df['STheta'].values < stheta_cut_off].values.ravel()\n",
        "X = X_df[X_df['STheta'].values < stheta_cut_off].values\n",
        "\n",
        "plt.scatter(X[:,0],y,label='STheta')  \n",
        "plt.scatter(X[:,1],y,label='Salnty')  \n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.xlabel('X values')\n",
        "plt.ylabel('y (STheta) values')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print('\\n Shape of y:   {}'.format(y.shape))\n",
        "print('\\n Shape of X:   {}'.format(X.shape))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEMCAYAAAAmgtofAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f210987ba58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Shape of y:   (812168,)\n",
            "\n",
            " Shape of X:   (812168, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Hn3hYauU-WvP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train and Test Data\n",
        "\n",
        "In order to test the performance of the model generated by the gradient descent, the data are split into a train and test set. The sklearn function, `train_test_split` is used, splits an input dataset randomly (with seed functionality) into a provided ratio.\n",
        "\n",
        "The predictors are also scaled using the sklearn Standard Scaler. This will  center the data around 0 and normalize the data to a standard deviation of 1. This is to help during the gradient descent. If the $X$' scales are wildly different, a small adjustment in one to determine the optimum gradient path may drastically overpower a small adjustment in the other. **The test set is scaled using the parameters from the training set, to avoid data leakage** When validating model fit, it is important to keep the validation / test set isolated so the model can not gain any additional information from the test set. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "wgajyqqJ-WvQ",
        "colab_type": "code",
        "outputId": "d076808c-91a3-477f-8622-ed8fdeed3c51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "cell_type": "code",
      "source": [
        "test_size = 0.3\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_size , random_state = 239)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scale = scaler.fit_transform(X_train)\n",
        "X_test_scale = scaler.transform(X_test)\n",
        "\n",
        "X_train_scale= np.column_stack([X_train_scale, np.ones([X_train_scale.shape[0], 1], dtype=np.int32)])\n",
        "X_test_scale = np.column_stack([X_test_scale, np.ones([X_test_scale.shape[0], 1], dtype=np.int32)])\n",
        "\n",
        "print(\"Training Data: {} of original dataset\".format(1-test_size)) \n",
        "print(\"y Data Shape: {}\".format(y_train.shape)) \n",
        "print(\"X Data Shape: {}\".format(X_train_scale.shape)) \n",
        "print(\"Scaled X Data:\\n {}\".format(pd.DataFrame(X_train_scale).describe())) \n",
        "\n",
        "print(\"\\n\\nTest Data: {} of original dataset\".format(test_size))\n",
        "print(\"y Data Shape: {}\".format(y_test.shape))\n",
        "print(\"X Data Shape: {}\".format(X_test_scale.shape))\n",
        "print(\"Scaled X Data: \\n {}\".format(pd.DataFrame(X_test_scale).describe()))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data: 0.7 of original dataset\n",
            "y Data Shape: (568517,)\n",
            "X Data Shape: (568517, 3)\n",
            "Scaled X Data:\n",
            "                   0             1         2\n",
            "count  5.685170e+05  5.685170e+05  568517.0\n",
            "mean   2.357253e-12  3.443218e-13       1.0\n",
            "std    1.000001e+00  1.000001e+00       0.0\n",
            "min   -1.171888e+01 -4.849723e+00       1.0\n",
            "25%   -7.638039e-01 -8.466356e-01       1.0\n",
            "50%    5.907173e-02  1.769714e-01       1.0\n",
            "75%    7.715088e-01  8.223104e-01       1.0\n",
            "max    6.910594e+00  2.303612e+00       1.0\n",
            "\n",
            "\n",
            "Test Data: 0.3 of original dataset\n",
            "y Data Shape: (243651,)\n",
            "X Data Shape: (243651, 3)\n",
            "Scaled X Data: \n",
            "                    0              1         2\n",
            "count  243651.000000  243651.000000  243651.0\n",
            "mean       -0.002104      -0.003176       1.0\n",
            "std         0.998328       1.000283       0.0\n",
            "min       -11.718877      -4.849723       1.0\n",
            "25%        -0.763804      -0.848621       1.0\n",
            "50%         0.054741       0.174986       1.0\n",
            "75%         0.765012       0.819332       1.0\n",
            "max         6.037913       2.248013       1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yg3l7Znd-WvX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now both the predictors in train set are centered around 0 with a standard deviation of 1. The test set is centered around *nearly* one with a standard deviation of *nearly* 1. This is to be expected as the data was **randomly split** into the train and test set."
      ]
    },
    {
      "metadata": {
        "id": "cKUP8r2o-Wvh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Minibatch Gradient Descent\n",
        "\n",
        "Next gradient descent is performed to find the model parameters, theta, which minimize the cost function. A mini-batch method was chosen to minimize computation time. The function uses a learning rate $eta$, and performs gradient descent over a set of predictors and response variables for a provided $epoch$ count. \n",
        "\n",
        "The parameters, theta, are then used to solve for the model predictions, yhat, which can then yield RMSE, R-squared and variance explained."
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "vKxuIh62-Wvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def grad_desc_minibatch_model(predictors, response, minibatch_sizes, eta = 0.1, epochs = 100):  \n",
        "    # minibatch size\n",
        "    # eta - learning rate\n",
        "    # epochs - number of epochs to run\n",
        "    m = len(predictors)\n",
        "        \n",
        "    thetas_final = []\n",
        "    \n",
        "    #for each batchsize in the batchize vector\n",
        "    for i, batch_size in enumerate(minibatch_sizes):\n",
        "      print('\\n Execution gradient descent {} using minibatch size of {} \\n'.format(i+1, minibatch_sizes[i]))\n",
        "      \n",
        "      #initialize random theta\n",
        "      theta = np.random.randn(3,1)\n",
        "      \n",
        "      #iterate over each epoch\n",
        "      for iteration in range(epochs):    \n",
        "          \n",
        "          #get random subsamples of length m\n",
        "          shuffled_indices = np.random.permutation(m)\n",
        "          X_b_shuffled = predictors[shuffled_indices]\n",
        "          y_shuffled = response[shuffled_indices]\n",
        "          \n",
        "          for i in range(0, m, batch_size):\n",
        "              \n",
        "              # set of shuffled Xs,Yx=s\n",
        "              xi = X_b_shuffled[i:i+batch_size]\n",
        "              yi = y_shuffled[i:i+batch_size]\n",
        "              \n",
        "              #determine gradient using blank equation\n",
        "              gradients = 2/batch_size * xi.T.dot(xi.dot(theta) - np.asmatrix(yi).T)\n",
        "              \n",
        "              #update theta by using the gradient vector and scaler learning rate\n",
        "              theta = theta - eta * gradients\n",
        "      \n",
        "      thetas_final.append(theta)\n",
        "\n",
        "    print('Finished!')\n",
        "    return thetas_final\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8rJCoq157y-t",
        "colab_type": "code",
        "outputId": "60a91669-a1a2-4199-8e70-cb5ab7e05474",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "minibatchs = [50,2000,10000] \n",
        "model_thetas_list = grad_desc_minibatch_model(X_train_scale, y_train, minibatchs) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Execution gradient descent 1 using minibatch size of 50 \n",
            "\n",
            "\n",
            " Execution gradient descent 2 using minibatch size of 2000 \n",
            "\n",
            "\n",
            " Execution gradient descent 3 using minibatch size of 10000 \n",
            "\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a6rZXDz5uVGI",
        "colab_type": "code",
        "outputId": "5d6f6cf5-f452-4e91-c3f3-cb585f4df45c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "def summarize_coeffs(list, col_names, index_values, header='Values'):  \n",
        "  for i, item in enumerate(list):\n",
        "    print('\\n{} : {}'.format(header, minibatchs[i]))\n",
        "    df = pd.DataFrame(item).round(3)\n",
        "    df.columns = col_names\n",
        "    df.rename(index=index_values, inplace=True)\n",
        "    print(df,'\\n')\n",
        "  return\n",
        " \n",
        "column_names = ['Coefficients']\n",
        "index_values = {0:'Salnty',1:'STheta', 2:'Intercept'}\n",
        "\n",
        "summarize_coeffs(model_thetas_list, column_names, index_values, 'MiniBatch Sizes')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "MiniBatch Sizes : 50\n",
            "           Coefficients\n",
            "Salnty            1.513\n",
            "STheta           -5.114\n",
            "Intercept        10.835 \n",
            "\n",
            "\n",
            "MiniBatch Sizes : 2000\n",
            "           Coefficients\n",
            "Salnty            1.431\n",
            "STheta           -5.060\n",
            "Intercept        10.848 \n",
            "\n",
            "\n",
            "MiniBatch Sizes : 10000\n",
            "           Coefficients\n",
            "Salnty            1.432\n",
            "STheta           -5.074\n",
            "Intercept        10.843 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xFHQI9ZPAB88",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model parameters from our gradient descent look very different from those found using the standard linear regression model. However, this is due to the fact we have trained our model (found the best fit parameters) using **scaled** data. We can evalue the performance of the model by comparing the scoring metrics from the first model. Below are functions to get the model metrics of interest."
      ]
    },
    {
      "metadata": {
        "id": "dfIFrn4tss8W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Fit"
      ]
    },
    {
      "metadata": {
        "id": "jwviL6gXwH2d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_stats(model_params, X, y):\n",
        "  \n",
        "  yhat = np.dot(X, model_params).T\n",
        "  residuals = np.square(np.subtract(yhat, y))\n",
        "  SSE = np.sum(residuals)\n",
        "  ybar = np.repeat(np.average(y), len(y))\n",
        "  SST = np.sum(np.square(np.subtract(ybar, y)))   \n",
        "  RMSE = np.sqrt(np.sum(np.square(yhat - y)) / len(y))\n",
        "  RSquared = 1 - (SSE/SST)  \n",
        "  \n",
        "  return RSquared, RMSE, residuals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qf-tPbLM24Rr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def plot_model_resids(residuals):\n",
        "    sns.set_style('whitegrid')\n",
        "    sns.distplot(residuals\n",
        "                 , hist=False\n",
        "                 , kde=True\n",
        "                 , bins=int(len(residuals/100))\n",
        "                 , color = 'darkblue'\n",
        "                 , hist_kws={'edgecolor':'black'}\n",
        "                 , kde_kws={'linewidth': 3})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0GaiSJ4KHCMX",
        "colab_type": "code",
        "outputId": "86894203-d6f3-44b6-be06-0c0de9808524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "def summarize_model(X, y, minibatchs, model_thetas_list):\n",
        "    RSquared = []\n",
        "    RMSE = []\n",
        "    Residuals = []\n",
        "\n",
        "    for i, item in enumerate(model_thetas_list):\n",
        "      rsquared, rmse, residuals = get_model_stats(item, X, y)\n",
        "      RSquared.append(rsquared)\n",
        "      RMSE.append(rmse)\n",
        "      Residuals.append(residuals)\n",
        "\n",
        "      print(\"\\nModel Scores using GD with minibatch size of : {}\".format(minibatchs[i]))\n",
        "      print(\"R-Squared :{}\".format(round(RSquared[i],4)))\n",
        "      print(\"RMSE :{}\".format(round(RMSE[i],4)))\n",
        "      print(\"VAF :{}\".format(round(RSquared[i],4)))\n",
        "    return RSquared, RMSE, Residuals\n",
        "\n",
        "Model_Squared, RMSE, Model_resids = summarize_model(X_train_scale, y_train, minibatchs, model_thetas_list)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model Scores using GD with minibatch size of : 50\n",
            "R-Squared :0.9867\n",
            "RMSE :0.4865\n",
            "VAF :0.9867\n",
            "\n",
            "Model Scores using GD with minibatch size of : 2000\n",
            "R-Squared :0.9869\n",
            "RMSE :0.4832\n",
            "VAF :0.9869\n",
            "\n",
            "Model Scores using GD with minibatch size of : 10000\n",
            "R-Squared :0.9869\n",
            "RMSE :0.4831\n",
            "VAF :0.9869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AvhzmZoCBTzM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These model scores are essentially identical to the Linear Regression models in Homework 1 for all minibatch sizes, more so for 2000, and 10000. This shows that our model using gradient descent has find the global minima of the cost function, which exists as a linear regression can be solved for using the normal equation\n",
        "\n",
        "Plot the residuals "
      ]
    },
    {
      "metadata": {
        "id": "X4FzvWPQ34Ai",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Model Validation\n",
        "\n",
        "In order to confirm the model has not been overfit, the preserved test dataset will be used to get predictions from the models generated using the train data. The model metrics, $R^2$ and $RMSE$ should remain consistent between the train and test data sets."
      ]
    },
    {
      "metadata": {
        "id": "uODhcKXv2jUn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "3f754775-dc6a-45b6-c9dc-10c03abfb6c2"
      },
      "cell_type": "code",
      "source": [
        "Model_R_Squared_test, RMSE_test, model_resids_test = summarize_model(X_test_scale, y_test, minibatchs, model_thetas_list)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model Scores using GD with minibatch size of : 50\n",
            "R-Squared:0.9866\n",
            "RMSE:0.488\n",
            "VAF:0.9866\n",
            "\n",
            "Model Scores using GD with minibatch size of : 2000\n",
            "R-Squared:0.9869\n",
            "RMSE:0.4824\n",
            "VAF:0.9869\n",
            "\n",
            "Model Scores using GD with minibatch size of : 10000\n",
            "R-Squared:0.9869\n",
            "RMSE:0.4824\n",
            "VAF:0.9869\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zp_gyOqpajUs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Summary"
      ]
    },
    {
      "metadata": {
        "id": "gdnWGn09-WwS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "All models have a consistent r squared between as train and test indicating no overfitting. All values are within a .01 of the parameters solved using the normal equation. Overall the gradient descent performs very well on this data set, even when using batch sizes of 50. The performance is on par with the the analytical solution and the epoch size could probably be reduced without losing too much performance, making the computation time even quicker."
      ]
    },
    {
      "metadata": {
        "id": "2KyCWbu-BAVB",
        "colab_type": "code",
        "outputId": "ef72fede-ad15-4565-c85a-de1625bc2f23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "!jupyter nbconvert --to html '$NOTEBOOK_FILE'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook /content/gdrive/My Drive/Code/Machine Learning & Predictive Analytics/Homework 2/Homework 2.ipynb to html\n",
            "[NbConvertApp] Writing 475156 bytes to /content/gdrive/My Drive/Code/Machine Learning & Predictive Analytics/Homework 2/Homework 2.html\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}